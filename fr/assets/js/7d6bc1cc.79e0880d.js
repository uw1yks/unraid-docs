"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4085],{1569:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>r,default:()=>d,frontMatter:()=>i,metadata:()=>a,toc:()=>l});var s=t(5893),o=t(1151);const i={sidebar_position:10},r="Cache/Pool issues",a={id:"unraid-os/troubleshooting/cache-issues",title:"Cache/Pool issues",description:"Mover is not moving files",source:"@site/docs/unraid-os/troubleshooting/cache-issues.md",sourceDirName:"unraid-os/troubleshooting",slug:"/unraid-os/troubleshooting/cache-issues",permalink:"/fr/unraid-os/troubleshooting/cache-issues",draft:!1,unlisted:!1,editUrl:"https://github.com/unraid/docs/tree/main/docs/unraid-os/troubleshooting/cache-issues.md",tags:[],version:"current",sidebarPosition:10,frontMatter:{sidebar_position:10},sidebar:"unraidSidebar",previous:{title:"UDMA CRC Errors",permalink:"/fr/unraid-os/troubleshooting/crc-errors"},next:{title:"FAQ",permalink:"/fr/category/faq"}},h={},l=[{value:"Mover is not moving files",id:"mover-is-not-moving-files",level:2}];function c(e){const n={em:"em",h1:"h1",h2:"h2",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"cachepool-issues",children:"Cache/Pool issues"}),"\n",(0,s.jsx)(n.h2,{id:"mover-is-not-moving-files",children:"Mover is not moving files"}),"\n",(0,s.jsxs)(n.p,{children:["The commonest cause for this is simply new users misunderstanding the\n",(0,s.jsx)(n.em,{children:"Use"})," ",(0,s.jsx)(n.em,{children:"Cache"})," setting for a share and getting the ",(0,s.jsx)(n.strong,{children:"Yes"})," and ",(0,s.jsx)(n.strong,{children:"Prefer"}),"\nsettings back-to-front. If you want files to initially be written to the\ncache and later moved to the array then you ned to use the ",(0,s.jsx)(n.strong,{children:"Yes"}),"\nsetting and not the ",(0,s.jsx)(n.strong,{children:"Prefer"})," setting."]}),"\n",(0,s.jsxs)(n.p,{children:["Another common mis-conception is that changing the ",(0,s.jsx)(n.em,{children:"Use Cache"})," setting\nto ",(0,s.jsx)(n.strong,{children:"Only"})," or ",(0,s.jsx)(n.strong,{children:"No"})," will trigger mover to transfer files to/from their\ncurrent location to match the new ",(0,s.jsx)(n.em,{children:"Use Cache"})," setting. In fact mover\ntakes no action on shares that have this setting so the files are left\nin their current location."]}),"\n",(0,s.jsxs)(n.p,{children:["Another point is not realizing that the Docker and VM services keep\ncertain files permanently open (particularly in the ",(0,s.jsx)(n.strong,{children:"system"}),",\n",(0,s.jsx)(n.strong,{children:"domains"}),", and ",(0,s.jsx)(n.strong,{children:"appdata"})," shares) and this can stop mover acting on\nthose files. It is not enough to simply stop all running containers\nand/or VMs - you actually need to disable the services themselves to\nallow such files to be moved."]}),"\n",(0,s.jsx)(n.p,{children:"###Files end up on a pool (cache) despite Use Cache=No setting for a share"}),"\n",(0,s.jsx)(n.p,{children:"This behaviour is the one that new users find most perplexing."}),"\n",(0,s.jsxs)(n.p,{children:["It arises when a 'move' action is attempted at the Linux level. (This\ncan be either from the command line or within a container (since all\ncontainer are Linux based).) It arises from the fact that Linux is not\naware of ",(0,s.jsx)(n.em,{children:"User Shares"})," combined with the way that Linux implements a\n'move' operation. If Linux thinks that both source and target are on\nthe same mount point (and all ",(0,s.jsx)(n.em,{children:"User Shares"})," are under the ",(0,s.jsx)(n.strong,{children:"/mnt/user"}),"\nmount point) then it first tries a ",(0,s.jsx)(n.em,{children:"rename"})," command and for speed and\nonly if that fails does it revert to trying a ",(0,s.jsx)(n.em,{children:"copy + delete"})," operation.\nIn the case of a cache/pool this 'rename' succeeds so the file is left\non the same drive but under a new folder name corresponding to the\ntarget share name. Since User Shares are simply an amalgamated view of\nthe top level folders on all drives this means that suddenly the file(s)\nin question can end up on a drive that has the ",(0,s.jsx)(n.em,{children:"Use Cache=No"})," setting.\nSince ",(0,s.jsx)(n.em,{children:"mover"})," ignores shares with the ",(0,s.jsx)(n.em,{children:"Use Cache"})," setting of ",(0,s.jsx)(n.em,{children:"No"})," or\n",(0,s.jsx)(n.em,{children:"Only"})," this will result in the files being left stranded on a pool that\nthe target share has not been configured to use for caching purposes."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"*This behaviour can also occur if you try and move files between two\nUser Shares that are set to use different Pools for caching purposes"}),".*\nOnce again this can result in the files ending up on the wrong pool."]}),"\n",(0,s.jsx)(n.p,{children:"Workarounds to this issue are by doing any of the following:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Manually move the file(s) in question to the drive where you want it\nto be finally located."}),"\n",(0,s.jsxs)(n.li,{children:["Set the share that the file has ended up in to have the ",(0,s.jsx)(n.em,{children:"Use\nCache=Yes"})," setting and then when mover runs the file will get\ntransferred to the array following the rules for that share to pick\nthe array drive. You can either start mover manually from the Main\ntab or wait until it runs automatically at its next scheduled time.\nOnce mover has been run you can either leave the ",(0,s.jsx)(n.em,{children:"Use Cache"})," setting\nas ",(0,s.jsx)(n.em,{children:"Yes"})," or change it to the setting you want to use long term."]}),"\n",(0,s.jsx)(n.li,{children:"Do an explicit copy + delete operation."}),"\n",(0,s.jsx)(n.li,{children:"Do the move over the network as at the network level two different\nUser Share will never appear to be on the same mount point so a\ncopy + delete is done automatically."}),"\n",(0,s.jsx)(n.li,{children:"Make sure the mount points for source and target appear to be\ndifferent at the Linux level."}),"\n",(0,s.jsx)(n.li,{children:"Move between physical drives rather than at the User Share level."}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},1151:(e,n,t)=>{t.d(n,{Z:()=>a,a:()=>r});var s=t(7294);const o={},i=s.createContext(o);function r(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);